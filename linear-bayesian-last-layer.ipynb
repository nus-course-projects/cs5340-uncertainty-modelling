{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Using Bayesian Neural Network\n",
    "\n",
    "This is only an example of using Bayesian Torch. I use CIFAR10 to simplify the example. So DON'T FORGET to change the dataset to MS-ASL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from bayesian_torch.models.dnn_to_bnn import dnn_to_bnn, get_kl_loss\n",
    "from bayesian_torch.layers.variational_layers.linear_variational import LinearReparameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_parameter_count(layer):\n",
    "  \"\"\"\n",
    "  Calculates the number of parameters in a single PyTorch layer.\n",
    "  Args:\n",
    "    layer: A PyTorch nn.Module layer.\n",
    "\n",
    "  Returns:\n",
    "    int: The number of parameters in the layer.\n",
    "  \"\"\"\n",
    "  return sum(p.numel() for p in layer.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uint8_to_float(image_tensor):\n",
    "    \"\"\"Converts a uint8 tensor to a float tensor in the range [0, 1].\"\"\"\n",
    "    return image_tensor.float() / 255.0\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Lambda(uint8_to_float),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import load_msasl\n",
    "\n",
    "batch_size = 1\n",
    "num_classes = 10\n",
    "\n",
    "# If you want to load a subset of the MSASL Dataset with n classes\n",
    "test_dataset, train_dataset, validation_dataset = load_msasl(\"data\", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Last Layer to Bayesian FC layer\n",
    "You can also use `dnn_to_bnn()` like the example IntelLabs gave. But I prefer this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bnn = torchvision.models.video.r3d_18(weights='DEFAULT')\n",
    "ori_in_features = model_bnn.fc.in_features\n",
    "ori_out_features = model_bnn.fc.out_features\n",
    "\n",
    "model_bnn.fc = LinearReparameterization(in_features=ori_in_features,\n",
    "                                out_features=num_classes,\n",
    "                                prior_mean=0,\n",
    "                                prior_variance=1,\n",
    "                                posterior_mu_init=0,\n",
    "                                posterior_rho_init=-3.0,\n",
    "                                bias=True)\n",
    "\n",
    "# Assign last layer as BNN\n",
    "model_bnn.fc.dnn_to_bnn_flag = True\n",
    "# If you didn't assign it, then you will get 2 outputs (out, kl) when you do the feedforward.\n",
    "\n",
    "model_bnn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Bayesian NN Parameters\n",
    "- Number of parameters will be doubled for each layer. $(inFeatures*outFeatures + bias) * 2$\n",
    "- Thus, we will have two weights for each layer, mu and rho (Section 3.2 of the paper)\n",
    "- Updating the weights using KL (Section 3.4 of the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = get_layer_parameter_count(model_bnn.fc)\n",
    "print(\"Number of Parameters:\\n\", num_params)\n",
    "print(\"Mu Weight:\\n\", model_bnn.fc.mu_weight)\n",
    "print(\"Rho Weight:\\n\", model_bnn.fc.rho_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Step\n",
    "Like usual. The only difference is you need to compute KL Loss to update the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_bnn.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    print(\"Number of train dataset:\", train_dataset)\n",
    "    for i, data in enumerate(train_dataset, 0):\n",
    "        video, label, metadata = train_dataset[i]\n",
    "        label = torch.LongTensor([label])\n",
    "        \n",
    "        # Transform video\n",
    "        video = video.unsqueeze(0)\n",
    "        video = transform(video)\n",
    "        video = video.transpose(1, 2)\n",
    "        video = video.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model_bnn(video).to(\"cpu\")\n",
    "        kl = get_kl_loss(model_bnn)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss = loss + kl / batch_size\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        print(f'[Epoch {epoch + 1}, Batch {i + 1:5d}] loss: {running_loss:.3f}')\n",
    "        running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-QH_zdfHZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
