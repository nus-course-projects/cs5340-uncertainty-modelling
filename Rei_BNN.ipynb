{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Colab version to train on T4 GPU:\n",
        "[https://colab.research.google.com/drive/1TRE6DIhLm5P6k1bdFxXlRpOvzfalH4zC#scrollTo=xfosNdAaoWeH](https://colab.research.google.com/drive/1TRE6DIhLm5P6k1bdFxXlRpOvzfalH4zC#scrollTo=xfosNdAaoWeH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4KiVX9QR0oEL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "import av\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "from bayesian_torch.models.dnn_to_bnn import dnn_to_bnn, get_kl_loss\n",
        "from bayesian_torch.layers.variational_layers.linear_variational import LinearReparameterization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdKvGfXf08NF",
        "outputId": "6e81576b-c2c0-496d-81e7-2a0374ee8128"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TRAIN] Loaded 3012 videos with top 100 labels\n",
            "[TEST] Loaded 458 videos with top 100 labels\n",
            "[VALIDATION] Loaded 815 videos with top 100 labels\n"
          ]
        }
      ],
      "source": [
        "from utils.dataset import load_msasl\n",
        "\n",
        "label_threshold = 100\n",
        "test_dataset, train_dataset, validation_dataset = load_msasl('bin', label_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch of videos: torch.Size([8, 64, 3, 224, 224])\n",
            "Batch of labels: torch.Size([8])\n",
            "Metadata sample: {'id': ['5c4907d5-07f9-4dd5-8d76-6e42e8d0f2e7', '8e933be6-40d2-4cce-b9e4-22751b1a6de4', '87926ff3-a734-4fa1-9369-5f327e1d7d8e', '39eba28a-fae8-4262-b34d-9112c079e2d7', '4f203dfd-6b08-49d4-8a32-adc29618418a', '59b45547-7016-4078-a1f5-982f65238b9a', '847a72a9-fef6-4cb6-853e-0dbf2799ae46', '132a4836-bca7-4146-b4e7-10425c95267f'], 'org_text': ['Friend', 'repeat/AGAIN', 'WATER', 'TABLE', 'TIRED', 'Brother', 'Cat', 'milk'], 'clean_text': ['friend', 'again', 'water', 'table', 'tired', 'brother', 'cat', 'milk'], 'signer_id': tensor([450,   0,  77,  32, 349,  32,  12, 152]), 'signer': tensor([55,  0, -1, 17, 10, 17,  6, 98]), 'file': ['ASL ABC Song  NEW with ASL Letters and Signs', 'repeatAGAIN', 'Unit 11 Vocabularymp4', 'ASL 1 Unit 3 Vocabulary', 'ASL 1st class VOCABULARY BUILDER', 'ASL 1 Unit 4 Vocabulary', 'Mastering ASL Unit 4 Vocabulary signed by Dr Wooten', 'Milk - Asl'], 'label': tensor([ 17,  26,  48,  28,  16,  34, 121,  32]), 'fps': tensor([25, 25, 25, 25, 25, 25, 25, 25]), 'url': ['https://www.youtube.com/watch?v=csBb71UPN8E', 'https://www.youtube.com/watch?v=oqQ8Nt5NvjQ', 'https://www.youtube.com/watch?v=PvzBgEcEPew', 'https://www.youtube.com/watch?v=KRrKqGEGdMg', 'https://www.youtube.com/watch?v=ZHUVt5W8UEk', 'https://www.youtube.com/watch?v=TwkGS9TjUX8&t=21s', 'https://www.youtube.com/watch?v=UXetwN_cI5A', 'https://www.youtube.com/watch?v=wjbWyQLPqwQ'], 'text': ['friend', 'again', 'water', 'table', 'tired', 'brother', 'cat', 'milk'], 'filename': ['friend_5c4907d5-07f9-4dd5-8d76-6e42e8d0f2e7', 'again_8e933be6-40d2-4cce-b9e4-22751b1a6de4', 'water_87926ff3-a734-4fa1-9369-5f327e1d7d8e', 'table_39eba28a-fae8-4262-b34d-9112c079e2d7', 'tired_4f203dfd-6b08-49d4-8a32-adc29618418a', 'brother_59b45547-7016-4078-a1f5-982f65238b9a', 'cat_847a72a9-fef6-4cb6-853e-0dbf2799ae46', 'milk_132a4836-bca7-4146-b4e7-10425c95267f']}\n",
            "tensor([12, 27, 20, 37, 23, 42, 50,  3])\n",
            "Batch of videos: torch.Size([8, 64, 3, 224, 224])\n",
            "Batch of labels: torch.Size([8])\n",
            "Metadata sample: {'id': ['4ec2257b-cee7-4240-9412-83237f39b021', 'd45e75c6-3a49-4f13-94ee-378e997ec147', '82f10f1f-5c07-45ca-9732-19d315e762c2', '75449e83-bc00-4351-8d7e-b8fe41284087', 'd915e9f3-34a8-4e12-ad5b-0d541b5c7071', '15a8a154-be54-43d9-91d7-a7cf21ad7507', '08168212-e203-4991-8243-bad734a01c79', 'eb155ca4-b168-4970-a780-419c2d7f7236'], 'org_text': ['chair', 'FRiEND', 'sister', 'sister', 'TEACHER', 'please', 'BOOK', 'no'], 'clean_text': ['sit', 'friend', 'sister', 'sister', 'teacher', 'please', 'book', 'no'], 'signer_id': tensor([125,  63, 125, 118,  63, 125, 140, 125]), 'signer': tensor([ 8, 24,  8, 32, 24,  8,  4,  8]), 'file': ['ASL I - Unit 9 Vocabulary Review', 'Family Voc Unit', 'ASL I - Unit 5 Vocabulary Review', 'ASL Family Signs', 'Aug to Oct Voc Captions', 'ASL I - Unit 1 Vocabulary', 'ASL - Classroom', 'ASL I - Unit 2 - Vocabulary'], 'label': tensor([18, 17, 11, 11,  2, 47, 38,  4]), 'fps': tensor([25, 25, 25, 25, 25, 25, 25, 25]), 'url': ['https://www.youtube.com/watch?v=f7tZegTJCWo', 'https://www.youtube.com/watch?v=GOczM9jk2xY', 'https://www.youtube.com/watch?v=JYF-AfMbUNw', 'https://www.youtube.com/watch?v=7m6N78E-5uE', 'https://www.youtube.com/watch?v=9g-hioQapYE', 'https://www.youtube.com/watch?v=2VB3WN8adyM', 'https://www.youtube.com/watch?v=UjiCWH8PSvM', 'https://www.youtube.com/watch?v=0bIF7jh6lnE'], 'text': ['sit', 'friend', 'sister', 'sister', 'teacher', 'please', 'book', 'no'], 'filename': ['sit_4ec2257b-cee7-4240-9412-83237f39b021', 'friend_d45e75c6-3a49-4f13-94ee-378e997ec147', 'sister_82f10f1f-5c07-45ca-9732-19d315e762c2', 'sister_75449e83-bc00-4351-8d7e-b8fe41284087', 'teacher_d915e9f3-34a8-4e12-ad5b-0d541b5c7071', 'please_15a8a154-be54-43d9-91d7-a7cf21ad7507', 'book_08168212-e203-4991-8243-bad734a01c79', 'no_eb155ca4-b168-4970-a780-419c2d7f7236']}\n",
            "tensor([69, 12,  9,  9,  7, 70, 56, 34])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "for videos, labels, metadata in data_loader:\n",
        "        print(f\"Batch of videos: {videos.shape}\") # (batch_size, 64, C, H, W)\n",
        "        print(f\"Batch of labels: {labels.shape}\") # (batch_size,)\n",
        "        print(f\"Metadata sample: {metadata}\") # Dictionary of metadata\n",
        "        print(labels)\n",
        "        break # Checking the first batch\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "\n",
        "\n",
        "\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "\n",
        "for videos, labels, metadata in validation_loader:\n",
        "        print(f\"Batch of videos: {videos.shape}\") # (B, T, C, H, W)\n",
        "        print(f\"Batch of labels: {labels.shape}\") # (batch_size,)\n",
        "        print(f\"Metadata sample: {metadata}\") # Dictionary of metadata\n",
        "        print(labels)\n",
        "        break # Checking the first batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8K4vii_N1IK1"
      },
      "outputs": [],
      "source": [
        "# test_dataset.show_video(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Print Train Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjheFoRKoVQa",
        "outputId": "dfc312fd-52e9-4d25-ee1d-b2f59f1c70a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num of GPU: 1\n",
            "_CudaDeviceProperties(name='NVIDIA GeForce RTX 3060 Laptop GPU', major=8, minor=6, total_memory=6143MB, multi_processor_count=30, uuid=a43e09d2-abbb-44a0-a8cb-9ebfcebe6d64, L2_cache_size=3MB)\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'num of GPU: {torch.cuda.device_count()}')\n",
        "    print(torch.cuda.get_device_properties(0))\n",
        "else:\n",
        "    print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xfosNdAaoWeH",
        "outputId": "a790d7f4-5cb8-4095-d8c6-97f813d90ee5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet18_GRU(\n",
              "  (feature_extractor): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (gru): GRU(512, 20, num_layers=2, batch_first=True)\n",
              "  (fc): Linear(in_features=20, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from model.RetNet18_GRU import ResNet18_GRU\n",
        "\n",
        "cnn_gru_model = ResNet18_GRU().to(device)\n",
        "cnn_gru_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "AALnMoD3LBoN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/12:   0%|          | 0/377 [00:39<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     41\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Gradient Clipping\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m cnn_gru_model.named_parameters():\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/cs5340-uncertainty-modelling/venv/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/cs5340-uncertainty-modelling/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/github/cs5340-uncertainty-modelling/venv/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer (Adam, no learning rate scheduler)\n",
        "optimizer = optim.Adam(cnn_gru_model.parameters(), lr=0.001)  # No scheduler\n",
        "\n",
        "# Scheduler\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "\n",
        "num_epochs = 12  # Adjust based on performance\n",
        "\n",
        "def check_nan(tensor, name):\n",
        "    if torch.isnan(tensor).any() or torch.isinf(tensor).any():\n",
        "        print(f\"⚠️ NaN or Inf detected in {name}!\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    cnn_gru_model.train()  # Set model to training mode\n",
        "    total_loss = 0\n",
        "\n",
        "    train_loader = tqdm(data_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=True)\n",
        "\n",
        "    for videos, labels, metadata in train_loader:\n",
        "        videos, labels = videos.to(device), labels.to(device)\n",
        "        \n",
        "        # Reset gradients\n",
        "        optimizer.zero_grad() \n",
        "        videos = videos.float() / 255.0\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = cnn_gru_model(videos)\n",
        "\n",
        "        # Check NaN values\n",
        "        for name, param in cnn_gru_model.named_parameters():\n",
        "            check_nan(param, f\"Param {name}\")\n",
        "        \n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient Clipping\n",
        "        for name, param in cnn_gru_model.named_parameters():\n",
        "            if param.grad is not None:\n",
        "                check_nan(param.grad, f\"Grad {name}\")\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(cnn_gru_model.parameters(), max_norm=5) # Gradient clipping\n",
        "\n",
        "        # Update model weights\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        train_loader.set_postfix(loss=loss.detach().item())  # Update tqdm display\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Validation step\n",
        "    cnn_gru_model.eval()\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    # Wrap validation loader with tqdm for validation progress\n",
        "    val_loader = tqdm(validation_loader, desc=\"Validating\", leave=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for videos, labels, metadata in test_loader:\n",
        "            videos = videos.to(device).float()  # Convert videos to float32\n",
        "            labels = labels.to(device).long()   # Convert labels to long\n",
        "            outputs = cnn_gru_model(videos)\n",
        "            predicted = torch.argmax(outputs, dim=1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Validation Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
