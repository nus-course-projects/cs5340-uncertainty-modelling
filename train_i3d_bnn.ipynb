{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_video\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from bayesian_torch.models.dnn_to_bnn import get_kl_loss\n",
    "\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    UniformTemporalSubsample,\n",
    "    Div255,\n",
    "    Normalize,\n",
    "    # ModuleNotFoundError: No module named 'torchvision.transforms.functional_tensor'\n",
    "    # If you see this error, you can install the latest version of torchvision from source.\n",
    "    # pip install torchvision\n",
    "    # pip install \"git+https://github.com/facebookresearch/pytorchvideo.git\"\n",
    ")\n",
    "\n",
    "from torchvision.transforms import Compose, Lambda, CenterCrop, Resize, RandomAffine\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.dataset import load_msasl, load_asl_citizen\n",
    "from utils.optical_flow import OpticalFlowTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 1\n",
    "num_workers = 0\n",
    "num_frames = 20\n",
    "num_epochs = 10\n",
    "learning_rate = 0.01\n",
    "num_classes = 100\n",
    "input_type = \"rgb\"\n",
    "frozen_layers = 5\n",
    "\n",
    "bayesian_layers = 3\n",
    "num_monte_carlo = 5 if bayesian_layers is not None else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Related Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomHorizontalFlip(nn.Module):\n",
    "    def __init__(self, p=0.5):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if random.random() < self.p:\n",
    "            return x.flip(3)\n",
    "        return x\n",
    "\n",
    "# A helper dataset wrapper that applies a transform to each sample.\n",
    "class TransformDataset(Dataset):\n",
    "    def __init__(self, dataset, transform):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset (Dataset): Original dataset returning (video, label, metadata)\n",
    "            transform (callable): Transformation to apply on a sample dict.\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video, label, metadata = self.dataset[idx]\n",
    "        sample = {\"video\": video, \"label\": label, \"metadata\": metadata}\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        # Return transformed video, label, and optionally metadata\n",
    "        return sample[\"video\"], sample[\"label\"], sample.get(\"metadata\", {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Transform Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Loaded 3012 videos with top 100 labels\n",
      "[TEST] Loaded 458 videos with top 100 labels\n",
      "[VALIDATION] Loaded 815 videos with top 100 labels\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"msasl\"\n",
    "\n",
    "test_dataset, train_dataset, validation_dataset = load_msasl(\"bin\", top_k_labels=num_classes)\n",
    "# ASL Dataset: load_asl_citizen(\"ASL_Citizen\", top_k_labels=num_classes)\n",
    "\n",
    "train_transform = ApplyTransformToKey(\n",
    "    key=\"video\",\n",
    "    transform=Compose([\n",
    "        OpticalFlowTransform() if input_type  == \"optical_flow\" else Lambda(lambda x: x),\n",
    "        Lambda(lambda x: x.permute(1, 0, 2, 3)),  # Convert (T,H,W,C) -> (C,T,H,W)\n",
    "        UniformTemporalSubsample(num_frames),\n",
    "        Resize(224),\n",
    "        RandomHorizontalFlip(),\n",
    "        Div255(),\n",
    "        Lambda(lambda x: (x-0.5)*2.0),\n",
    "    ])\n",
    ")\n",
    "test_transform = ApplyTransformToKey(\n",
    "    key=\"video\",\n",
    "    transform=Compose([\n",
    "        OpticalFlowTransform() if input_type  == \"optical_flow\" else Lambda(lambda x: x),\n",
    "        Lambda(lambda x: x.permute(1, 0, 2, 3)),  # Convert (T,H,W,C) -> (C,T,H,W)\n",
    "        UniformTemporalSubsample(num_frames),\n",
    "        Resize(224),\n",
    "        Div255(),\n",
    "        Lambda(lambda x: (x-0.5)*2.0),\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap each dataset with the transformation.\n",
    "train_dataset = TransformDataset(train_dataset, train_transform)\n",
    "validation_dataset = TransformDataset(validation_dataset, test_transform)\n",
    "test_dataset = TransformDataset(test_dataset, test_transform)\n",
    "\n",
    "# Create DataLoaders.\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Related Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device, num_monte_carlo=10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    tqdm_dataloader = tqdm(dataloader, desc=\"Training batches\", leave=False)\n",
    "    for videos, labels, _ in tqdm_dataloader:\n",
    "        videos = videos.to(device)\n",
    "        labels = labels.to(device)\n",
    "        B, T, C, H, W = videos.shape\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output_mc = []\n",
    "        kl_loss_mc = []\n",
    "        for _ in range(num_monte_carlo):\n",
    "            outputs = model(videos)\n",
    "            output_mc.append(outputs)\n",
    "            kl_loss = get_kl_loss(model)\n",
    "            kl_loss_mc.append(kl_loss)\n",
    "        outputs = torch.stack(output_mc, dim=0).mean(dim=0)\n",
    "        kl_loss = torch.stack(kl_loss_mc, dim=0).mean(dim=0)\n",
    "\n",
    "        loss = criterion(outputs, labels) + kl_loss / B\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * videos.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        \n",
    "        tqdm_dataloader.set_postfix(loss=loss.item(), kl_loss=kl_loss.item(), correct=correct/total)\n",
    "        \n",
    "    epoch_loss = running_loss / total if total > 0 else float('inf')\n",
    "    epoch_acc = correct / total if total > 0 else 0\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def validate_epoch(model, dataloader, criterion, device, num_monte_carlo=10):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        tqdm_dataloader = tqdm(dataloader, desc=\"Validation batches\", leave=False)\n",
    "        for videos, labels, _ in tqdm_dataloader:\n",
    "            output_mc = []\n",
    "            videos = videos.to(device)\n",
    "            labels = labels.to(device)\n",
    "            for _ in range(num_monte_carlo):\n",
    "                outputs = model(videos)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item() * videos.size(0)\n",
    "                output_mc.append(outputs)\n",
    "            total += labels.size(0)\n",
    "            output_mc = torch.stack(output_mc, dim=0).mean(dim=0)\n",
    "            _, preds = torch.max(output_mc, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            tqdm_dataloader.set_postfix(loss=loss.item(), correct=correct/total)\n",
    "            \n",
    "    epoch_loss = running_loss / total if total > 0 else float('inf')\n",
    "    epoch_acc = correct / total if total > 0 else 0\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pre-trained I3D weights from /opt/CS5340_Project/temp/rgb_imagenet.pt\n",
      "Convert layer MaxPool3d_5a_2x2 into Bayesian Layer\n",
      "Convert layer Mixed_5b into Bayesian Layer\n",
      "Convert layer Mixed_5c into Bayesian Layer\n"
     ]
    }
   ],
   "source": [
    "from model.I3D_bayesian import InceptionI3d\n",
    "\n",
    "model_name = \"I3D\"\n",
    "\n",
    "if input_type == \"rgb\":\n",
    "    model = InceptionI3d(num_classes=num_classes, frozen_layers=frozen_layers, bayesian_layers=bayesian_layers)\n",
    "elif input_type == \"optical_flow\":\n",
    "    model = InceptionI3d(num_classes=num_classes, frozen_layers=frozen_layers, bayesian_layers=bayesian_layers, in_channels=2, input_type=\"optical_flow\")\n",
    "else:\n",
    "    raise ValueError(f\"Invalid input type for I3D: {input_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InceptionI3d(\n",
       "  (avg_pool): AvgPool3d(kernel_size=[2, 7, 7], stride=(1, 1, 1), padding=0)\n",
       "  (logits): Unit3D(\n",
       "    (conv3d): Conv3d(1024, 100, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       "  (Conv3d_1a_7x7): Unit3D(\n",
       "    (conv3d): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(2, 2, 2), bias=False)\n",
       "    (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (MaxPool3d_2a_3x3): MaxPool3dSamePadding(kernel_size=[1, 3, 3], stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv3d_2b_1x1): Unit3D(\n",
       "    (conv3d): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "    (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv3d_2c_3x3): Unit3D(\n",
       "    (conv3d): Conv3d(64, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "    (bn): BatchNorm3d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (MaxPool3d_3a_3x3): MaxPool3dSamePadding(kernel_size=[1, 3, 3], stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (Mixed_3b): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(192, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(96, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(192, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(192, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_3c): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(128, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(256, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(32, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (MaxPool3d_4a_3x3): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (Mixed_4b): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(480, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(480, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(96, 208, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(208, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(480, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(16, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(480, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_4c): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(512, 160, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(512, 112, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(112, 224, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(512, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(24, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(512, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_4d): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(512, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(24, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(512, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_4e): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(512, 112, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(512, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(144, 288, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(512, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_4f): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3d(528, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3d(528, 160, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3d(160, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(320, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3d(528, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3d(32, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3d(528, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (MaxPool3d_5a_2x2): MaxPool3dSamePadding(kernel_size=[2, 2, 2], stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (Mixed_5b): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3dReparameterization()\n",
       "      (bn): BatchNorm3d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3dReparameterization()\n",
       "      (bn): BatchNorm3d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3dReparameterization()\n",
       "      (bn): BatchNorm3d(320, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3dReparameterization()\n",
       "      (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3dReparameterization()\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3dReparameterization()\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionModule(\n",
       "    (b0): Unit3D(\n",
       "      (conv3d): Conv3dReparameterization()\n",
       "      (bn): BatchNorm3d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1a): Unit3D(\n",
       "      (conv3d): Conv3dReparameterization()\n",
       "      (bn): BatchNorm3d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b1b): Unit3D(\n",
       "      (conv3d): Conv3dReparameterization()\n",
       "      (bn): BatchNorm3d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2a): Unit3D(\n",
       "      (conv3d): Conv3dReparameterization()\n",
       "      (bn): BatchNorm3d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b2b): Unit3D(\n",
       "      (conv3d): Conv3dReparameterization()\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (b3b): Unit3D(\n",
       "      (conv3d): Conv3dReparameterization()\n",
       "      (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Train Loss: 13.8163, Train Acc: 0.0110 | Val Loss: 23.4185, Val Acc: 0.0074\n",
      "New best model saved with Val Acc: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: Train Loss: 4.8215, Train Acc: 0.0126 | Val Loss: 23.1529, Val Acc: 0.0110\n",
      "New best model saved with Val Acc: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: Train Loss: 4.7296, Train Acc: 0.0113 | Val Loss: 23.0630, Val Acc: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: Train Loss: 4.6586, Train Acc: 0.0106 | Val Loss: 23.2253, Val Acc: 0.0184\n",
      "New best model saved with Val Acc: 0.0184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: Train Loss: 4.6477, Train Acc: 0.0139 | Val Loss: 23.1070, Val Acc: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: Train Loss: 4.6480, Train Acc: 0.0100 | Val Loss: 23.1063, Val Acc: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: Train Loss: 4.6561, Train Acc: 0.0093 | Val Loss: 23.0462, Val Acc: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: Train Loss: 4.6469, Train Acc: 0.0106 | Val Loss: 23.0543, Val Acc: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: Train Loss: 4.6470, Train Acc: 0.0139 | Val Loss: 23.0811, Val Acc: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: Train Loss: 4.6452, Train Acc: 0.0116 | Val Loss: 23.0825, Val Acc: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, num_monte_carlo)\n",
    "    val_loss, val_acc = validate_epoch(model, val_loader, criterion, device, num_monte_carlo)\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Save the best model based on validation accuracy.\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), f\"best_{model_name}_fl{frozen_layers}_bl{bayesian_layers}_{dataset_name}\")\n",
    "        print(f\"New best model saved with Val Acc: {best_val_acc:.4f}\")\n",
    "    \n",
    "    metrics.append({\"train_loss\": train_loss, \"train_acc\": train_acc, \"val_loss\": val_loss, \"val_acc\": val_acc, \"best_val_acc\": best_val_acc})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-QH_zdfHZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
